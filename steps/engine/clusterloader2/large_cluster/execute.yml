parameters:
  - name: cloud
    type: string
    default: ""
  - name: engine_input
    type: object
    default: {}
  - name: region
    type: string

steps:
  - script: |
      set -eo pipefail

      PYTHONPATH=$PYTHONPATH:$(pwd) python3 $PYTHON_SCRIPT_FILE configure \
        --cpu_per_node $CPU_PER_NODE \
        --node_count $NODE_COUNT \
        --node_per_step $NODE_PER_STEP \
        --pods_per_node ${PODS_PER_NODE:-0} \
        --repeats $REPEATS \
        --operation_timeout $SCALE_TIMEOUT \
        --provider $CLOUD \
        --cilium_enabled $CILIUM_ENABLED \
        --scrape_containerd ${SCRAPE_CONTAINERD:-False} \
        --cl2_override_file ${CL2_CONFIG_DIR}/overrides.yaml
      PYTHONPATH=$PYTHONPATH:$(pwd) python3 $PYTHON_SCRIPT_FILE execute \
        --cl2_image ${CL2_IMAGE} \
        --cl2_config_dir ${CL2_CONFIG_DIR} \
        --cl2_report_dir $CL2_REPORT_DIR \
        --cl2_config_file $CL2_CONFIG_FILE \
        --kubeconfig ${HOME}/.kube/config \
        --provider $CLOUD \
        --scrape_containerd ${SCRAPE_CONTAINERD:-False}
    workingDirectory: modules/python
    env:
      ${{ if eq(parameters.cloud, 'azure') }}:
        CLOUD: aks
      ${{ else }}:
        CLOUD: ${{ parameters.cloud }}
      REGION: ${{ parameters.region }}
      PYTHON_SCRIPT_FILE: $(Pipeline.Workspace)/s/modules/python/clusterloader2/large_cluster/large_cluster.py
      CL2_IMAGE: ${{ parameters.engine_input.image }}
      CL2_CONFIG_DIR: $(Pipeline.Workspace)/s/modules/python/clusterloader2/large_cluster/config
      CL2_REPORT_DIR: $(Pipeline.Workspace)/s/modules/python/clusterloader2/large_cluster/results
    displayName: "Run Benchmark"
