parameters:
- name: region
  type: string
- name: role
  type: string
- name: nodes_per_nodepool
  type: string
- name: enable_autoscale
  type: string

steps:
- script: |
    set -euo pipefail
    set -x

    region=${{ parameters.region }}

    aks_name=$(az resource list --resource-type Microsoft.ContainerService/managedClusters --location $region \
      --query "[?(tags.run_id == '${RUN_ID}' && tags.role == '$ROLE')].name" --output tsv)

    aks_rg=$(az resource list --resource-type Microsoft.ContainerService/managedClusters --location $region \
      --query "[?(tags.run_id == '${RUN_ID}' && tags.role == '$ROLE')].resourceGroup" --output tsv)

    if [ -z "$aks_name" ]; then
        echo "##vso[task.logissue type=error;] No AKS instance with role $ROLE and tag $RUN_ID found in region $region."
        exit 1
    fi
    az aks get-credentials -n $aks_name -g $aks_rg

    nodepools=$(az aks nodepool list --cluster-name $aks_name --resource-group $aks_rg -o json)
    usernodepools=$(echo $nodepools | jq -r '.[] | select(.mode == "User" and .name != "promnodepool" and (.name | contains("devtest") | not)) | .name')

    for np in $usernodepools; do
      currentnodes=$(az aks nodepool show --cluster-name $aks_name --name $np --resource-group $aks_rg | jq '.count')

      # disable autoscaler before scaling nodepool to desire node count
      az aks nodepool update --cluster-name $aks_name --name $np --resource-group $aks_rg --disable-cluster-autoscaler
      if [ "$currentnodes" != "${{ parameters.nodes_per_nodepool }}" ]; then
        az aks nodepool scale --cluster-name $aks_name --name $np --resource-group $aks_rg -c ${{ parameters.nodes_per_nodepool }}
      fi

      # turn on autoscaler if test necessitates it
      if [ "true" =  "${{ parameters.enable_autoscale }}" ]; then
         az aks nodepool update --cluster-name $aks_name --name $np --resource-group $aks_rg --enable-cluster-autoscaler --min-count 0 --max-count 50
      fi
      az aks nodepool update --cluster-name $aks_name --name $np --resource-group $aks_rg --node-taints "slo=true:NoSchedule" --labels slo=true
      sleep 300
    done
  env:
    ROLE: ${{ parameters.role }}
  displayName: "Scale Cluster"
  condition: or(ne(variables['SWIFTV2PING'], 'false'), ne(variables['SWIFTV2'], 'false'))

