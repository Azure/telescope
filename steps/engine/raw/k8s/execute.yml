parameters:
  result_dir: ""
  vm_size: ""
  create_node_count: ""
  scale_node_count: ""
  scale_step_up_count: ""
  pool_name: ""
  cloud: ""
  step_time_out: 600
  gpu_node_pool: false

steps:
- script: |
    set -eo pipefail

    ARGS=(
      "$PYTHON_SCRIPT_FILE"
      all
      --run-id "$RUN_ID"
      --node-pool-name "$POOL_NAME"
      --node-count "$CREATE_NODE_COUNT"
      --target-count "$SCALE_NODE_COUNT"
      --vm-size "$VM_SIZE"
      --step-timeout "$STEP_TIME_OUT"
      --result-dir "$RESULT_DIR"
      --step-size "$SCALE_STEP_UP_COUNT"
    )

    # Conditionally add gpu-node
    if [[ "$GPU_NODE_POOL" == "True" ]]; then
      ARGS+=(--gpu-node-pool)
    fi
    if [[ "$SCALE_STEP_UP_COUNT" != "$SCALE_NODE_COUNT" ]]
    then
      ARGS+=(--progressive)
    fi

    # Run the command
    PYTHONPATH=$PYTHONPATH:$(pwd) python3 "${ARGS[@]}"
  displayName: 'Execute K8s CRUD Operations for ${{ parameters.cloud }}'
  workingDirectory: modules/python
  env:
    PYTHON_SCRIPT_FILE: $(Pipeline.Workspace)/s/modules/python/k8s/${{ parameters.cloud }}/node_pool_crud.py
    VM_SIZE: ${{ parameters.vm_size }}
    CREATE_NODE_COUNT: ${{ parameters.create_node_count }}
    SCALE_NODE_COUNT: ${{ parameters.scale_node_count }}
    SCALE_STEP_UP_COUNT: ${{ parameters.scale_step_up_count }}
    POOL_NAME: ${{ parameters.pool_name }}
    CLOUD: ${{ parameters.cloud }}
    STEP_TIME_OUT: 600
    RESULT_DIR: $(System.DefaultWorkingDirectory)/$(RUN_ID)
    GPU_NODE_POOL: ${{ parameters.gpu_node_pool }}
    AZURE_MI_SUBSCRIPTION_ID: $(AZURE_SUBSCRIPTION_ID)
