parameters:
- name: cloud
  type: string
  default: ''
- name: credential_type
  type: string
  default: 'service_connection'

steps:
- script: |
    set -eo pipefail
    set -x

    # Ensure output directory exists with proper permissions
    # Directory may be owned by root from Docker volume mount, so use sudo
    echo "Ensuring output directory: ${OUTPUT_DIR}"
    sudo mkdir -p "${OUTPUT_DIR}"
    sudo chmod 777 "${OUTPUT_DIR}"
    
    echo "Output directory ready: ${OUTPUT_DIR}"

    # Verify controller is running
    echo "Checking controller pods..."
    kubectl get pods -n perf-ns -l app=datapath-controller
    kubectl logs -n perf-ns -l app=datapath-controller --tail=20 || true
    
    # Port forward to datapath-controller deployment
    echo "Starting port-forward to datapath-controller..."
    kubectl port-forward -n perf-ns deployment/datapath-controller 8082:8082 &
    PF_PID=$!
    
    # Cleanup port-forward on exit
    trap "kill $PF_PID 2>/dev/null || true" EXIT
    
    # Wait for port-forward to be ready
    sleep 5
    
    # Test connectivity
    echo "Testing API connectivity..."
    curl -v "http://localhost:8082/api/v1/time-to-start?topN=1&namespace=slo-1" || true
    
    # Query time-to-start metrics
    echo "Querying time-to-start metrics..."
    time_to_start_response=$(curl -s "http://localhost:8082/api/v1/time-to-start?topN=10&namespace=slo-1")
    echo "API Response (time-to-start):"
    echo "$time_to_start_response"
    echo "$time_to_start_response" > "${OUTPUT_DIR}/datapath-time-to-start.json"
    
    # Query time-to-datapath-ready metrics
    echo "Querying time-to-datapath-ready metrics..."
    time_to_dp_ready_response=$(curl -s "http://localhost:8082/api/v1/time-to-datapath-ready?topN=10&namespace=slo-1")
    echo "API Response (time-to-datapath-ready):"
    echo "$time_to_dp_ready_response"
    echo "$time_to_dp_ready_response" > "${OUTPUT_DIR}/datapath-time-to-dp-ready.json"
    
    # Query pod-health metrics
    echo "Querying pod-health metrics..."
    pod_health_response=$(curl -s "http://localhost:8082/api/v1/pod-health?topN=10&namespace=slo-1")
    echo "API Response (pod-health):"
    echo "$pod_health_response"
    echo "$pod_health_response" > "${OUTPUT_DIR}/datapath-pod-health.json"
    
    # Print summary
    echo "=== Time to Start Summary ==="
    cat "${OUTPUT_DIR}/datapath-time-to-start.json" | jq '{totalSuccessful, totalFailed, p50, p90, p99}'
    
    echo "=== Time to Datapath Ready Summary ==="
    cat "${OUTPUT_DIR}/datapath-time-to-dp-ready.json" | jq '{totalSuccessful, totalFailed, p50, p90, p99}'
    
    echo "=== Pod Health Summary ==="
    cat "${OUTPUT_DIR}/datapath-pod-health.json" | jq '{desiredReplicas, runningPods, pendingPods, failedPods, successPct}'
    
    # Merge datapath results into results.json
    if [ -f "${RESULTS_FILE}" ]; then
      echo "Merging datapath metrics into ${RESULTS_FILE}..."
      
      # Extract template fields from first line of results.json
      template=$(head -n 1 "${RESULTS_FILE}" | jq 'del(.group, .measurement, .result)')
      
      # Add time-to-start metrics
      time_to_start=$(cat "${OUTPUT_DIR}/datapath-time-to-start.json")
      echo "$template" | jq --argjson data "$time_to_start" \
        '. + {group: "datapath", measurement: "TimeToStart", result: $data}' \
        >> "${RESULTS_FILE}"
      
      # Add time-to-datapath-ready metrics
      time_to_dp_ready=$(cat "${OUTPUT_DIR}/datapath-time-to-dp-ready.json")
      echo "$template" | jq --argjson data "$time_to_dp_ready" \
        '. + {group: "datapath", measurement: "TimeToDatapathReady", result: $data}' \
        >> "${RESULTS_FILE}"
      
      # Add pod-health metrics
      pod_health=$(cat "${OUTPUT_DIR}/datapath-pod-health.json")
      echo "$template" | jq --argjson data "$pod_health" \
        '. + {group: "datapath", measurement: "PodHealth", result: $data}' \
        >> "${RESULTS_FILE}"
      
      echo "Datapath metrics merged successfully"
    else
      echo "##vso[task.logissue type=warning;]File ${RESULTS_FILE} does not exist. Skipping merge."
    fi
    
    echo "Results saved to ${OUTPUT_DIR}"
  env:
    OUTPUT_DIR: $(Pipeline.Workspace)/s/modules/python/clusterloader2/swiftv2-slo/results
    RESULTS_FILE: $(TEST_RESULTS_FILE)
  displayName: "Collect Datapath Observer Results"

