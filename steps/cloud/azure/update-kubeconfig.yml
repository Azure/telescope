parameters:
- name: region
  type: string
- name: role
  type: string
- name: alias
  type: string
  default: ""

steps:
# Public cluster: fetch kubeconfig locally on agent
- script: |
    set -euo pipefail
    set -x

    region=${{ parameters.region }}

    aks_name=$(az resource list --resource-type Microsoft.ContainerService/managedClusters --location $region \
      --query "[?(tags.run_id == '${RUN_ID}' && tags.role == '$ROLE')].name" --output tsv)

    aks_rg=$(az resource list --resource-type Microsoft.ContainerService/managedClusters --location $region \
      --query "[?(tags.run_id == '${RUN_ID}' && tags.role == '$ROLE')].resourceGroup" --output tsv)

    if [ -z "$aks_name" ]; then
        echo "##vso[task.logissue type=error;] No AKS instance with role $ROLE and tag $RUN_ID found in region $region."
        exit 1
    fi

    az aks get-credentials -n $aks_name -g $aks_rg ${ALIAS:+--context $ALIAS}
  env:
    ROLE: ${{ parameters.role }}
    ALIAS: ${{ parameters.alias }}
  displayName: "Update kubeconfig (local)"
  condition: eq(variables['JUMPBOX_HOST'], '')

# Private cluster: fetch kubeconfig on jumpbox via SSH
# Jumpbox uses Managed Identity for Azure authentication
- script: |
    set -euo pipefail
    
    # SSH_KEY_PATH is set by steps/ssh/setup-key.yml
    if [ -z "${SSH_KEY_PATH:-}" ] || [ ! -f "$SSH_KEY_PATH" ]; then
      echo "SSH_KEY_PATH is not set or file not found: ${SSH_KEY_PATH:-'(not set)'}" >&2
      exit 1
    fi
    
    ssh_target="${JUMPBOX_USERNAME}@${JUMPBOX_HOST}"
    ssh_opts=(-i "$SSH_KEY_PATH" -o "StrictHostKeyChecking=no" -o "UserKnownHostsFile=/dev/null")
    
    region="${{ parameters.region }}"
    
    echo "Fetching kubeconfig on jumpbox for AKS with role '$ROLE' in region '$region'..."
    echo "Using SSH key: $SSH_KEY_PATH"
    echo "Jumpbox: $ssh_target"
    
    # Wait for cloud-init to complete (installs az cli, kubectl, etc.)
    echo "Waiting for cloud-init to complete on jumpbox..."
    if ! ssh "${ssh_opts[@]}" "$ssh_target" "cloud-init status --wait"; then
      echo "Warning: cloud-init finished with errors, but continuing anyway..."
    fi
    echo "Cloud-init completed."
    
    # Use Managed Identity on jumpbox for Azure authentication
    ssh -tt "${ssh_opts[@]}" "$ssh_target" "set -euo pipefail && \
      echo 'Logging in with Managed Identity...' && \
      az login --identity --output none && \
      echo 'Login successful. Finding AKS cluster...' && \
      aks_name=\$(az resource list --resource-type Microsoft.ContainerService/managedClusters --location '$region' \
        --query \"[?(tags.run_id == '${RUN_ID}' && tags.role == '$ROLE')].name\" --output tsv) && \
      aks_rg=\$(az resource list --resource-type Microsoft.ContainerService/managedClusters --location '$region' \
        --query \"[?(tags.run_id == '${RUN_ID}' && tags.role == '$ROLE')].resourceGroup\" --output tsv) && \
      if [ -z \"\$aks_name\" ]; then echo 'No AKS found with run_id=${RUN_ID} and role=$ROLE'; exit 1; fi && \
      echo \"Found AKS: \$aks_name in resource group: \$aks_rg\" && \
      az aks get-credentials -n \$aks_name -g \$aks_rg ${ALIAS:+--context $ALIAS} --overwrite-existing --file=/home/azureuser/.kube/config && \
      echo 'Kubeconfig updated on jumpbox. Testing kubectl...' && \
      kubectl get ns && \
      echo 'Waiting for cluster to stabilize...' && \
      sleep 120 && \
      echo 'Ready to proceed.' && \
      echo 'Pre-populating kubelogin cache...' && \
      TOKEN=\$(kubelogin get-token --environment AzurePublicCloud --login msi --server-id 6dae42f8-4368-4678-94ff-3960e28e3630 | jq -r '.status.token') && \
      kubectl config set-credentials user2 --token=\"\$TOKEN\" --kubeconfig=/home/azureuser/.kube/config && \
      kubectl config set-context \$aks_name --user=user2 --kubeconfig=/home/azureuser/.kube/config && \
      echo 'Done.'" 2>&1
  env:
    ROLE: ${{ parameters.role }}
    ALIAS: ${{ parameters.alias }}
  displayName: "Update kubeconfig (via Jumpbox)"
  condition: ne(variables['JUMPBOX_HOST'], '')

